{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Media Downloader\n",
    "\n",
    "This notebook provides an agentic way to download images and videos from Instagram posts using your authenticated session.\n",
    "\n",
    "## Features\n",
    "- Automated login to Instagram\n",
    "- Navigate through posts\n",
    "- Intercept network requests to capture media URLs\n",
    "- Download images and videos\n",
    "\n",
    "## Requirements\n",
    "Install the required packages first:\n",
    "```bash\n",
    "pip install selenium requests pillow webdriver-manager\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install selenium requests pillow webdriver-manager --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloads will be saved to: d:\\OneDrive - Emory\\Schweidel\\PerceptionMap\\code\\instagram_downloads\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DOWNLOAD_FOLDER = \"instagram_downloads\"\n",
    "MOBILE_VIEW = True  # Toggle Chrome's device toolbar (Ctrl+Shift+M) to keep Instagram in mobile layout\n",
    "\n",
    "# Create download folder\n",
    "Path(DOWNLOAD_FOLDER).mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Downloads will be saved to: {os.path.abspath(DOWNLOAD_FOLDER)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instagram Media Downloader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class InstagramMediaDownloader:\n    def __init__(self, mobile_view=True, headless=False, debug=False):\n        self.download_folder = DOWNLOAD_FOLDER\n        self.driver = None\n        self.mobile_view = mobile_view\n        self.headless = headless\n        self.debug = debug  # Enable verbose logging to verify network capture\n\n    def setup_driver(self):\n        \"\"\"Setup Chrome driver with appropriate options\"\"\"\n        chrome_options = Options()\n\n        if self.headless:\n            chrome_options.add_argument('--headless=new')\n\n        # Enable mobile emulation if requested\n        if self.mobile_view:\n            mobile_emulation = {\n                \"deviceMetrics\": {\"width\": 360, \"height\": 640, \"pixelRatio\": 3.0},\n                \"userAgent\": \"Mozilla/5.0 (Linux; Android 10) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Mobile Safari/537.36\"\n            }\n            chrome_options.add_experimental_option(\"mobileEmulation\", mobile_emulation)\n            \n            # Auto-open DevTools for easy inspection\n            chrome_options.add_argument(\"--auto-open-devtools-for-tabs\")\n\n        chrome_options.set_capability('goog:loggingPrefs', {'performance': 'ALL'})\n        chrome_options.add_argument('--no-sandbox')\n        chrome_options.add_argument('--disable-dev-shm-usage')\n        chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n        chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n\n        service = Service(ChromeDriverManager().install())\n        self.driver = webdriver.Chrome(service=service, options=chrome_options)\n        self.driver.implicitly_wait(10)\n        \n        if self.mobile_view:\n            print(\"✓ Driver setup complete (mobile emulation enabled, DevTools open)\")\n        else:\n            print(\"✓ Driver setup complete\")\n\n    def _drain_performance_logs(self):\n        \"\"\"Clear accumulated performance logs to avoid stale entries\"\"\"\n        if not self.driver:\n            return\n        try:\n            self.driver.get_log('performance')\n        except Exception:\n            pass\n\n    def _click_if_present(self, locator, timeout=5):\n        \"\"\"Click an element if it becomes clickable within timeout\"\"\"\n        try:\n            element = WebDriverWait(self.driver, timeout).until(\n                EC.element_to_be_clickable(locator)\n            )\n            element.click()\n            time.sleep(1)\n            return True\n        except Exception:\n            return False\n\n    def login(self, username, password):\n        \"\"\"Login to Instagram\"\"\"\n        print(\"Logging in to Instagram...\")\n        self.driver.get(\"https://www.instagram.com/accounts/login/\")\n        time.sleep(3)\n        \n        wait = WebDriverWait(self.driver, 20)\n        try:\n            # Handle cookie consent if present\n            self._click_if_present(\n                (By.XPATH, \"//button[contains(text(), 'Allow') or contains(text(), 'Accept')]\"),\n                timeout=5\n            )\n            \n            # Enter credentials\n            username_input = wait.until(EC.presence_of_element_located((By.NAME, \"username\")))\n            password_input = wait.until(EC.presence_of_element_located((By.NAME, \"password\")))\n            \n            username_input.send_keys(username)\n            password_input.send_keys(password)\n            password_input.send_keys(Keys.RETURN)\n            \n            time.sleep(5)\n            \n            # Handle post-login prompts\n            self._click_if_present((By.XPATH, \"//button[contains(text(), 'Not Now')]\"), timeout=3)\n            self._click_if_present((By.XPATH, \"//button[contains(text(), 'Not now')]\"), timeout=3)\n            \n            print(\"✓ Login successful\")\n            return True\n            \n        except Exception as exc:\n            print(f\"✗ Login failed: {str(exc)}\")\n            return False\n\n    def navigate_to_post(self, post_url):\n        \"\"\"Navigate to a specific Instagram post\"\"\"\n        print(f\"Navigating to post: {post_url}\")\n        self.driver.get(post_url)\n        time.sleep(3)\n        print(\"✓ Post loaded\")\n\n    def _wait_for_media_to_render(self, timeout=10):\n        \"\"\"Wait for post media elements to appear\"\"\"\n        try:\n            WebDriverWait(self.driver, timeout).until(\n                EC.presence_of_element_located((By.CSS_SELECTOR, \"article img, article video\"))\n            )\n        except TimeoutException:\n            pass\n\n    def _is_desired_media(self, url, mime_type, response):\n        \"\"\"Check if a media URL is desired (excludes static assets, profile pics, etc.)\"\"\"\n        if not url or ('image' not in mime_type and 'video' not in mime_type):\n            return False\n        \n        # Must be from Instagram CDN\n        if 'cdninstagram.com' not in url and 'fbcdn.net' not in url:\n            return False\n        \n        # Exclude static assets (logos, icons, UI elements)\n        if 'static.cdninstagram.com' in url:\n            return False\n        \n        path = urlparse(url).path.lower()\n        \n        # Exclude common non-media assets\n        excluded_tokens = ('profilepic', 'sprite', 'favicon', 'glyph', 'badge', 'logo', 'emoji')\n        if any(token in path for token in excluded_tokens):\n            return False\n        \n        # Size check for images (exclude small thumbnails/icons)\n        headers = response.get('headers', {})\n        content_length = headers.get('content-length') or headers.get('Content-Length')\n        if content_length and 'video' not in mime_type:\n            try:\n                if int(content_length) < 35000:\n                    return False\n            except ValueError:\n                pass\n        \n        return True\n\n    def _normalize_url(self, url):\n        \"\"\"Normalize URL for deduplication by removing certain query parameters\"\"\"\n        # Parse the URL\n        parsed = urlparse(url)\n        # Keep the main URL without query params for comparison\n        # This helps catch duplicates that differ only in tracking params\n        base_url = f\"{parsed.scheme}://{parsed.netloc}{parsed.path}\"\n        return base_url\n\n    def extract_media_urls_from_logs(self, debug_prefix=\"\"):\n        \"\"\"Extract media URLs from browser performance logs\"\"\"\n        if not self.driver:\n            return []\n        try:\n            logs = self.driver.get_log('performance')\n        except Exception:\n            return []\n        \n        if self.debug:\n            print(f\"\\n{debug_prefix}[DEBUG] Processing {len(logs)} performance log entries...\")\n        \n        media_urls = []\n        image_count = 0\n        video_count = 0\n        filtered_out = []\n        \n        for log_entry in logs:\n            try:\n                message = json.loads(log_entry['message'])['message']\n            except (KeyError, json.JSONDecodeError):\n                continue\n            \n            if message.get('method') != 'Network.responseReceived':\n                continue\n            \n            response = message.get('params', {}).get('response', {})\n            url = response.get('url', '')\n            mime_type = response.get('mimeType', '')\n            \n            if self._is_desired_media(url, mime_type, response):\n                media_type = 'video' if 'video' in mime_type else 'image'\n                media_urls.append({\n                    'url': url,\n                    'type': media_type,\n                    'normalized_url': self._normalize_url(url)\n                })\n                if media_type == 'video':\n                    video_count += 1\n                else:\n                    image_count += 1\n                    \n                if self.debug:\n                    filename = url.split('/')[-1].split('?')[0]\n                    if len(filename) > 50:\n                        filename = filename[:50] + \"...\"\n                    print(f\"{debug_prefix}  ✓ ACCEPTED {media_type}: {filename}\")\n            else:\n                # Track why it was filtered\n                if self.debug and url and ('image' in mime_type or 'video' in mime_type):\n                    reason = \"\"\n                    if 'static.cdninstagram.com' in url:\n                        reason = \"static CDN\"\n                    elif 'cdninstagram.com' not in url and 'fbcdn.net' not in url:\n                        reason = \"not Instagram CDN\"\n                    else:\n                        path = urlparse(url).path.lower()\n                        excluded_tokens = ('profilepic', 'sprite', 'favicon', 'glyph', 'badge', 'logo', 'emoji')\n                        for token in excluded_tokens:\n                            if token in path:\n                                reason = f\"contains '{token}'\"\n                                break\n                        if not reason:\n                            headers = response.get('headers', {})\n                            content_length = headers.get('content-length') or headers.get('Content-Length')\n                            if content_length and 'video' not in mime_type:\n                                try:\n                                    if int(content_length) < 35000:\n                                        reason = f\"too small ({content_length} bytes)\"\n                                except ValueError:\n                                    pass\n                    if reason:\n                        filename = url.split('/')[-1].split('?')[0]\n                        if len(filename) > 40:\n                            filename = filename[:40] + \"...\"\n                        filtered_out.append((filename, reason))\n        \n        if self.debug:\n            print(f\"{debug_prefix}[DEBUG] Found {image_count} images, {video_count} videos\")\n            if filtered_out and len(filtered_out) > 0:\n                print(f\"{debug_prefix}[DEBUG] Filtered out {len(filtered_out)} items:\")\n                for filename, reason in filtered_out[:5]:  # Show first 5\n                    print(f\"{debug_prefix}  ✗ {filename} - {reason}\")\n                if len(filtered_out) > 5:\n                    print(f\"{debug_prefix}  ... and {len(filtered_out) - 5} more\")\n        \n        return media_urls\n\n    def _click_next_slide(self):\n        \"\"\"Click the Next button in a carousel post\"\"\"\n        selectors = [\n            (By.CSS_SELECTOR, \"button[aria-label='Next']\"),\n            (By.XPATH, \"//button[@aria-label='Next']\"),\n            (By.XPATH, \"//button//*[name()='svg' and @aria-label='Next']/..\"),\n        ]\n        for locator in selectors:\n            try:\n                button = WebDriverWait(self.driver, 2).until(\n                    EC.element_to_be_clickable(locator)\n                )\n                button.click()\n                time.sleep(2)\n                return True\n            except Exception:\n                continue\n        return False\n\n    def _collect_carousel_media(self):\n        \"\"\"\n        Collect media from carousel by clicking Next through all items.\n        Does NOT download immediately - only collects URLs.\n        At the end, deduplicates and returns unique media items.\n        \"\"\"\n        all_media = []  # All media found (may have duplicates)\n        \n        if self.debug:\n            print(\"\\n\" + \"=\"*60)\n            print(\"STARTING MEDIA COLLECTION\")\n            print(\"=\"*60)\n            print(\"Compare the URLs below with what you see in Network tab > Img/Media\")\n        \n        # Wait for initial media to load\n        self._wait_for_media_to_render()\n        time.sleep(2)\n        \n        # Collect initial media (after refresh)\n        if self.debug:\n            print(\"\\n--- INITIAL LOAD (after refresh) ---\")\n        initial_media = self.extract_media_urls_from_logs(debug_prefix=\"[INITIAL] \")\n        all_media.extend(initial_media)\n        print(f\"Found {len(initial_media)} media item(s) on initial load\")\n        \n        # Drain logs to start fresh\n        self._drain_performance_logs()\n        \n        # Click Next and collect media progressively\n        click_count = 0\n        max_clicks = 50  # Safety limit\n        no_new_media_count = 0\n        \n        while click_count < max_clicks:\n            # Try to click Next\n            if not self._click_next_slide():\n                print(\"No more Next button found - reached end of carousel\")\n                break\n                \n            click_count += 1\n            self._wait_for_media_to_render()\n            time.sleep(1.5)\n            \n            if self.debug:\n                print(f\"\\n--- AFTER NEXT CLICK #{click_count} ---\")\n            \n            # Collect media from this iteration\n            current_media = self.extract_media_urls_from_logs(debug_prefix=f\"[NEXT-{click_count}] \")\n            \n            if len(current_media) > 0:\n                all_media.extend(current_media)\n                print(f\"After Next click {click_count}: Found {len(current_media)} media item(s) in logs\")\n                no_new_media_count = 0\n            else:\n                no_new_media_count += 1\n                print(f\"After Next click {click_count}: No new media in logs\")\n                \n                # If we've clicked 3 times with no new media, stop\n                if no_new_media_count >= 3:\n                    print(\"No new media for 3 consecutive clicks - stopping\")\n                    break\n            \n            # Drain logs after each collection\n            self._drain_performance_logs()\n        \n        if click_count >= max_clicks:\n            print(f\"⚠ Reached maximum click limit ({max_clicks})\")\n        \n        # NOW deduplicate based on normalized URL\n        if self.debug:\n            print(\"\\n\" + \"=\"*60)\n            print(\"DEDUPLICATION PHASE\")\n            print(\"=\"*60)\n            print(f\"Total media items collected: {len(all_media)}\")\n        \n        unique_media = []\n        seen_urls = set()\n        \n        for media in all_media:\n            normalized = media['normalized_url']\n            if normalized not in seen_urls:\n                seen_urls.add(normalized)\n                unique_media.append({\n                    'url': media['url'],\n                    'type': media['type']\n                })\n                if self.debug:\n                    filename = media['url'].split('/')[-1].split('?')[0][:50]\n                    print(f\"  ✓ UNIQUE {media['type']}: {filename}\")\n            else:\n                if self.debug:\n                    filename = media['url'].split('/')[-1].split('?')[0][:50]\n                    print(f\"  ✗ DUPLICATE {media['type']}: {filename}\")\n        \n        if self.debug:\n            print(f\"\\nAfter deduplication: {len(unique_media)} unique media items\")\n            print(\"=\"*60)\n        \n        print(f\"\\n✓ Collection complete: {len(unique_media)} unique media items (removed {len(all_media) - len(unique_media)} duplicates)\")\n        \n        return unique_media\n\n    def _extract_likes_and_comments(self):\n        \"\"\"Extract likes and comments count from the current post\"\"\"\n        likes = None\n        comments = None\n        \n        try:\n            # Extract likes - look for button with like text or specific patterns\n            try:\n                # Try to find likes in various formats\n                like_patterns = [\n                    \"span.x1ypdohk.x1s688f.x2fvf9.xe9ewy2[role='button']\",\n                    \"section a[href*='/liked_by/']\",\n                    \"a[href*='/liked_by/'] span\",\n                ]\n                \n                for pattern in like_patterns:\n                    elements = self.driver.find_elements(By.CSS_SELECTOR, pattern)\n                    for elem in elements:\n                        text = elem.text.strip()\n                        # Look for numbers in the text\n                        import re\n                        numbers = re.findall(r'\\d+', text)\n                        if numbers:\n                            likes = int(numbers[0])\n                            break\n                    if likes is not None:\n                        break\n            except Exception:\n                pass\n            \n            # Extract comments - look for comment count patterns\n            try:\n                comment_patterns = [\n                    \"span.html-span.xdj266r.x14z9mp.xat24cr.x1lziwak.xexx8yu.xyri2b.x18d9i69.x1c1uobl.x1hl2dhg.x16tdsg8.x1vvkbs\",\n                    \"span.xdj266r\",\n                    \"ul li div span\",\n                ]\n                \n                for pattern in comment_patterns:\n                    elements = self.driver.find_elements(By.CSS_SELECTOR, pattern)\n                    for elem in elements:\n                        text = elem.text.strip()\n                        # Only consider pure numbers (not mixed text)\n                        if text.isdigit():\n                            potential_comments = int(text)\n                            # Comments are usually larger than single digits\n                            if potential_comments > 0:\n                                comments = potential_comments\n                                break\n                    if comments is not None:\n                        break\n            except Exception:\n                pass\n                    \n        except Exception as e:\n            print(f\"⚠ Could not extract likes/comments: {e}\")\n        \n        return likes, comments\n\n    def download_media(self, media_list, post_id=None, likes=None, comments=None):\n        \"\"\"Download media files\"\"\"\n        if not media_list:\n            print(\"No media found to download\")\n            return []\n        \n        downloaded_files = []\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        \n        # Display post stats\n        if likes is not None or comments is not None:\n            stats = []\n            if likes is not None:\n                stats.append(f\"{likes} likes\")\n            if comments is not None:\n                stats.append(f\"{comments} comments\")\n            print(f\"\\nPost stats: {', '.join(stats)}\")\n        \n        if self.debug:\n            print(\"\\n\" + \"=\"*60)\n            print(\"STARTING DOWNLOADS\")\n            print(\"=\"*60)\n        \n        for idx, media in enumerate(media_list):\n            time.sleep(2)\n            try:\n                url = media['url']\n                media_type = media['type']\n                extension = 'mp4' if media_type == 'video' else 'jpg'\n                \n                if post_id:\n                    filename = f\"{post_id}_{idx+1}_{timestamp}.{extension}\"\n                else:\n                    filename = f\"media_{idx+1}_{timestamp}.{extension}\"\n                \n                filepath = os.path.join(self.download_folder, filename)\n                \n                print(f\"Downloading {media_type} {idx+1}/{len(media_list)}: {filename}\")\n                \n                if self.debug:\n                    url_preview = url[:80] + \"...\" if len(url) > 80 else url\n                    print(f\"  URL: {url_preview}\")\n                \n                response = requests.get(url, stream=True, timeout=30)\n                response.raise_for_status()\n                \n                with open(filepath, 'wb') as f:\n                    for chunk in response.iter_content(chunk_size=8192):\n                        f.write(chunk)\n                \n                downloaded_files.append(filepath)\n                print(f\"✓ Downloaded: {filename}\")\n                \n            except Exception as exc:\n                print(f\"✗ Failed to download {media.get('type', 'media')}: {str(exc)}\")\n        \n        return downloaded_files\n\n    def download_post(self, post_url):\n        \"\"\"Download all media from a single post\"\"\"\n        self.navigate_to_post(post_url)\n        \n        # Drain old logs and refresh page to clear network tab\n        self._drain_performance_logs()\n        print(\"Refreshing page to clear network logs...\")\n        self.driver.refresh()\n        time.sleep(3)\n        \n        self._wait_for_media_to_render()\n        \n        if self.debug:\n            print(\"\\n[DEBUG] After refresh, check Network tab > Img/Media sub-tabs\")\n            print(\"[DEBUG] The filenames shown there should match what we capture below\\n\")\n        \n        # Extract likes and comments\n        likes, comments = self._extract_likes_and_comments()\n        \n        # Collect media by navigating through carousel (NO downloading yet)\n        media_items = self._collect_carousel_media()\n        \n        post_id = post_url.rstrip('/').split('/')[-1]\n        # Remove query parameters from post_id\n        if '?' in post_id:\n            post_id = post_id.split('?')[0]\n            \n        print(f\"\\nReady to download {len(media_items)} unique media file(s)\")\n        \n        # NOW download the deduplicated media\n        downloaded = self.download_media(media_items, post_id, likes, comments)\n        return downloaded\n\n    def download_multiple_posts(self, post_urls):\n        \"\"\"Download media from multiple posts\"\"\"\n        all_downloads = []\n        for index, url in enumerate(post_urls, 1):\n            print(f\"\\n{'='*60}\")\n            print(f\"Processing post {index}/{len(post_urls)}\")\n            print(f\"{'='*60}\")\n            try:\n                self._drain_performance_logs()\n                downloaded = self.download_post(url)\n                all_downloads.extend(downloaded)\n                time.sleep(2)\n            except Exception as exc:\n                print(f\"✗ Error processing post: {str(exc)}\")\n        return all_downloads\n\n    def close(self):\n        \"\"\"Close the browser\"\"\"\n        if self.driver:\n            self.driver.quit()\n            print(\"\\n✓ Browser closed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Usage Example 1: Download from a Single Post\n\n**Debug Mode**: Set `debug=True` to see detailed logging that shows:\n- All URLs captured from performance logs\n- Which URLs are accepted and which are filtered out (with reasons)\n- This lets you verify the captured URLs match what you see in Network tab > Img/Media sub-tabs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize the downloader with DEBUG MODE enabled\n# Debug mode shows you exactly what URLs are being captured so you can verify\n# they match what you see in DevTools Network tab > Img/Media sub-tabs\ndownloader = InstagramMediaDownloader(mobile_view=MOBILE_VIEW, headless=False, debug=True)\ndownloader.setup_driver()\n\n# Login (replace with your credentials)\nUSERNAME = \"your_username\"  # Replace with your Instagram username\nPASSWORD = \"your_password\"  # Replace with your Instagram password\n\nif downloader.login(USERNAME, PASSWORD):\n    # Download from a single post\n    POST_URL = \"https://www.instagram.com/p/DOfLxX1j11j/?img_index=1\" # \"https://www.instagram.com/p/POST_ID/\"  # Replace with actual post URL\n    \n    downloaded_files = downloader.download_post(POST_URL)\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Download Complete!\")\n    print(f\"{'='*60}\")\n    print(f\"Total files downloaded: {len(downloaded_files)}\")\n    for file in downloaded_files:\n        print(f\"  - {file}\")\n\n# Close the browser\ndownloader.close()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mathias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}