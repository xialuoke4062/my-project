{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Multi-User Scraper\n",
    "Downloads all media from Instagram posts with stats tracking, login support, and duplicate detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "USERNAME = \"\"  # Your Instagram username\n",
    "PASSWORD = \"\"  # Your Instagram password\n",
    "DOWNLOAD_DIR = Path(\"instagram_downloads\")\n",
    "DOWNLOAD_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# List of usernames to scrape\n",
    "USERS_TO_SCRAPE = []  # e.g., [\"user1\", \"user2\", \"user3\"]\n",
    "\n",
    "# Global tracking\n",
    "downloaded_hashes = set()\n",
    "stats_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Chrome with mobile emulation and DevTools\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--auto-open-devtools-for-tabs')\n",
    "options.add_experimental_option('mobileEmulation', {\n",
    "    'deviceName': 'iPhone 12 Pro'\n",
    "})\n",
    "\n",
    "# Selenium 4.x compatible logging setup\n",
    "options.set_capability('goog:loggingPrefs', {'performance': 'ALL', 'browser': 'ALL'})\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "print(\"✓ Browser opened with DevTools enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Instagram\n",
    "def login_instagram(username, password):\n",
    "    driver.get('https://www.instagram.com/')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        # Wait for and click login button if on homepage\n",
    "        try:\n",
    "            login_link = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//a[contains(@href, '/accounts/login')]\"))\n",
    "            )\n",
    "            login_link.click()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Enter username\n",
    "        username_input = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"username\"))\n",
    "        )\n",
    "        username_input.send_keys(username)\n",
    "        \n",
    "        # Enter password\n",
    "        password_input = driver.find_element(By.NAME, \"password\")\n",
    "        password_input.send_keys(password)\n",
    "        password_input.send_keys(Keys.RETURN)\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Handle \"Save Your Login Info\" popup\n",
    "        try:\n",
    "            not_now = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Not now') or contains(text(), 'Not Now')]\"))\n",
    "            )\n",
    "            not_now.click()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Handle \"Turn on Notifications\" popup\n",
    "        try:\n",
    "            not_now = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Not Now')]\"))\n",
    "            )\n",
    "            not_now.click()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print(\"✓ Logged in successfully\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Login failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Perform login\n",
    "if USERNAME and PASSWORD:\n",
    "    login_instagram(USERNAME, PASSWORD)\n",
    "else:\n",
    "    print(\"⚠ No login credentials provided - will try without login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract post stats\n",
    "def extract_post_stats():\n",
    "    likes = \"0\"\n",
    "    comments = \"0\"\n",
    "    is_paid = False\n",
    "    \n",
    "    try:\n",
    "        # Get likes - multiple possible selectors\n",
    "        try:\n",
    "            like_spans = driver.find_elements(By.CSS_SELECTOR, 'span.x1ypdohk.x1s688f.x2fvf9.xe9ewy2[role=\"button\"]')\n",
    "            if like_spans:\n",
    "                likes = like_spans[0].text\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Alternative: look for \"likes\" text\n",
    "        if likes == \"0\":\n",
    "            try:\n",
    "                like_elements = driver.find_elements(By.XPATH, \"//*[contains(text(), 'like')]/span\")\n",
    "                for elem in like_elements:\n",
    "                    text = elem.text\n",
    "                    if text.replace(',', '').isdigit():\n",
    "                        likes = text\n",
    "                        break\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # Get comments\n",
    "        comment_spans = driver.find_elements(\n",
    "            By.CSS_SELECTOR,\n",
    "            'span.xdj266r.x14z9mp.xat24cr.x1lziwak.xexx8yu.xyri2b.x18d9i69.x1c1uobl.x1hl2dhg.x16tdsg8.x1vvkbs'\n",
    "        )\n",
    "        for span in comment_spans:\n",
    "            text = span.text\n",
    "            if text.replace(',', '').isdigit():\n",
    "                comments = text\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # Check for paid partnership\n",
    "        if \"Paid partnership with \" in driver.page_source:\n",
    "            is_paid = True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return likes, comments, is_paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click through carousel\n",
    "def click_through_carousel():\n",
    "    click_count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            # Try multiple selectors for next button\n",
    "            next_btn = None\n",
    "            selectors = [\n",
    "                'button[aria-label=\"Next\"]',\n",
    "                'button[aria-label=\"next\"]',\n",
    "                'button._afxw._al46._al47',\n",
    "                'button.coreSpriteRightChevron'\n",
    "            ]\n",
    "            \n",
    "            for selector in selectors:\n",
    "                try:\n",
    "                    next_btn = WebDriverWait(driver, 1).until(\n",
    "                        EC.element_to_be_clickable((By.CSS_SELECTOR, selector))\n",
    "                    )\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if next_btn:\n",
    "                next_btn.click()\n",
    "                click_count += 1\n",
    "                time.sleep(0.5)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        except (TimeoutException, NoSuchElementException):\n",
    "            break\n",
    "    \n",
    "    return click_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract media URLs from network logs (Selenium 4.x compatible)\n",
    "def extract_media_urls():\n",
    "    media_urls = set()\n",
    "    \n",
    "    try:\n",
    "        # Selenium 4.x method to get logs\n",
    "        logs = driver.get_log('performance')\n",
    "        \n",
    "        for log in logs:\n",
    "            try:\n",
    "                message = json.loads(log['message'])['message']\n",
    "                if message['method'] == 'Network.responseReceived':\n",
    "                    response = message['params']['response']\n",
    "                    url = response['url']\n",
    "                    mime_type = response.get('mimeType', '')\n",
    "                    \n",
    "                    if 'image/' in mime_type or 'video/' in mime_type:\n",
    "                        if 'cdninstagram.com' in url or 'fbcdn.net' in url:\n",
    "                            media_urls.add(url)\n",
    "            except:\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Could not extract from network logs: {e}\")\n",
    "        print(\"  Trying alternative method...\")\n",
    "        \n",
    "        # Fallback: extract from page source\n",
    "        try:\n",
    "            # Find img and video tags\n",
    "            images = driver.find_elements(By.TAG_NAME, 'img')\n",
    "            videos = driver.find_elements(By.TAG_NAME, 'video')\n",
    "            \n",
    "            for img in images:\n",
    "                src = img.get_attribute('src')\n",
    "                if src and ('cdninstagram.com' in src or 'fbcdn.net' in src):\n",
    "                    media_urls.add(src)\n",
    "            \n",
    "            for video in videos:\n",
    "                src = video.get_attribute('src')\n",
    "                if src and ('cdninstagram.com' in src or 'fbcdn.net' in src):\n",
    "                    media_urls.add(src)\n",
    "        except Exception as e2:\n",
    "            print(f\"  Fallback also failed: {e2}\")\n",
    "    \n",
    "    return media_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download media with duplicate detection\n",
    "def download_media(media_urls, post_dir):\n",
    "    success_count = 0\n",
    "    \n",
    "    for idx, url in enumerate(media_urls, 1):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Check for duplicates by content hash\n",
    "            content_hash = hashlib.md5(response.content).hexdigest()\n",
    "            if content_hash in downloaded_hashes:\n",
    "                print(f\"  Skipped {idx}/{len(media_urls)}: Duplicate\")\n",
    "                continue\n",
    "            \n",
    "            downloaded_hashes.add(content_hash)\n",
    "            \n",
    "            # Determine file extension\n",
    "            content_type = response.headers.get('content-type', '')\n",
    "            if 'video' in content_type:\n",
    "                ext = '.mp4'\n",
    "            elif 'image' in content_type:\n",
    "                ext = '.jpg'\n",
    "            else:\n",
    "                ext = '.jpg'  # default\n",
    "            \n",
    "            success_count += 1\n",
    "            filename = post_dir / f\"item_{success_count}{ext}\"\n",
    "            \n",
    "            filename.write_bytes(response.content)\n",
    "            print(f\"  Downloaded {success_count}: {filename.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Skipped {idx}/{len(media_urls)}: {str(e)[:40]}\")\n",
    "    \n",
    "    return success_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape a single post\n",
    "def scrape_post(post_url):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Scraping: {post_url}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    driver.get(post_url)\n",
    "    time.sleep(3)\n",
    "    driver.refresh()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Extract stats\n",
    "    likes, comments, is_paid = extract_post_stats()\n",
    "    print(f\"Stats: Likes={likes}, Comments={comments}, Paid={is_paid}\")\n",
    "    \n",
    "    # Click through carousel\n",
    "    click_count = click_through_carousel()\n",
    "    if click_count > 0:\n",
    "        print(f\"Clicked next {click_count} times\")\n",
    "    \n",
    "    # Extract media URLs\n",
    "    media_urls = extract_media_urls()\n",
    "    print(f\"Found {len(media_urls)} potential media items\")\n",
    "    \n",
    "    # Create directory for this post\n",
    "    post_id = post_url.rstrip('/').split('/')[-1]\n",
    "    post_dir = DOWNLOAD_DIR / post_id\n",
    "    post_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Download media\n",
    "    success_count = download_media(media_urls, post_dir)\n",
    "    \n",
    "    # Log stats\n",
    "    stats_log.append({\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'post_url': post_url,\n",
    "        'post_id': post_id,\n",
    "        'likes': likes,\n",
    "        'comments': comments,\n",
    "        'paid_partnership': is_paid,\n",
    "        'media_downloaded': success_count\n",
    "    })\n",
    "    \n",
    "    print(f\"✓ Downloaded {success_count} unique items to '{post_dir}'\")\n",
    "    return success_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape user profile\n",
    "def scrape_user(username, max_posts=None):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Scraping user: {username}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    profile_url = f\"https://www.instagram.com/{username}/\"\n",
    "    driver.get(profile_url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Scroll to load posts\n",
    "    for _ in range(3):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Find all post links\n",
    "    try:\n",
    "        post_links = []\n",
    "        \n",
    "        # Find all links with /p/ (posts)\n",
    "        links = driver.find_elements(By.CSS_SELECTOR, 'a[href*=\"/p/\"]')\n",
    "        \n",
    "        for link in links:\n",
    "            href = link.get_attribute('href')\n",
    "            if href and '/p/' in href:\n",
    "                post_links.append(href)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        post_links = list(dict.fromkeys(post_links))\n",
    "        \n",
    "        if max_posts:\n",
    "            post_links = post_links[:max_posts]\n",
    "        \n",
    "        print(f\"Found {len(post_links)} posts\")\n",
    "        \n",
    "        # Scrape each post\n",
    "        total_downloaded = 0\n",
    "        for i, post_url in enumerate(post_links, 1):\n",
    "            print(f\"\\nPost {i}/{len(post_links)}\")\n",
    "            count = scrape_post(post_url)\n",
    "            total_downloaded += count\n",
    "            time.sleep(2)\n",
    "        \n",
    "        print(f\"\\n✓ User '{username}' complete: {total_downloaded} total items downloaded\")\n",
    "        return total_downloaded\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping user: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main scraping loop - Scrape all users in the list\n",
    "if USERS_TO_SCRAPE:\n",
    "    for username in USERS_TO_SCRAPE:\n",
    "        scrape_user(username, max_posts=None)  # Set max_posts if needed\n",
    "        time.sleep(3)\n",
    "else:\n",
    "    print(\"⚠ No users to scrape. Add usernames to USERS_TO_SCRAPE list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stats log\n",
    "if stats_log:\n",
    "    stats_file = DOWNLOAD_DIR / \"scrape_stats.json\"\n",
    "    with open(stats_file, 'w') as f:\n",
    "        json.dump(stats_log, f, indent=2)\n",
    "    print(f\"\\n✓ Stats saved to {stats_file}\")\n",
    "    print(f\"\\nTotal stats:\")\n",
    "    print(f\"  Posts scraped: {len(stats_log)}\")\n",
    "    print(f\"  Items downloaded: {sum(s['media_downloaded'] for s in stats_log)}\")\n",
    "    print(f\"  Paid partnerships: {sum(1 for s in stats_log if s['paid_partnership'])}\")\n",
    "else:\n",
    "    print(\"No stats to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close browser\n",
    "driver.quit()\n",
    "print(\"\\n✓ Browser closed\")\n",
    "print(\"✓ All done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
